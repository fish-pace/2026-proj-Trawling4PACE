{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üõ∞Ô∏è NASA PACE OCI Data Downloader\n",
    "\n",
    "**Para o projeto LAG-FISH - Hackweek 2026**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Instalado!\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Install\n",
    "import sys, subprocess\n",
    "pkgs = [\"earthaccess\", \"pandas\", \"xarray\", \"netCDF4\", \"h5netcdf\", \"h5py\", \"ipywidgets\", \"aiohttp\"]\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + pkgs + [\"--quiet\"])\n",
    "print(\"‚úì Instalado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earthaccess 0.15.1\n",
      "  RRS: Remote Sensing Reflectance\n",
      "  CHL: Chlorophyll-a\n",
      "  POC: Particulate Organic Carbon\n",
      "  CARBON: Phytoplankton Carbon\n",
      "  IOP: Inherent Optical Properties\n",
      "  KD: Diffuse Attenuation\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Imports\n",
    "import os, re, tempfile\n",
    "import earthaccess\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display, clear_output\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PACE_PRODUCTS = {\n",
    "    'RRS': {'short_name': 'PACE_OCI_L3M_RRS', 'description': 'Remote Sensing Reflectance'},\n",
    "    'CHL': {'short_name': 'PACE_OCI_L3M_CHL', 'description': 'Chlorophyll-a'},\n",
    "    'POC': {'short_name': 'PACE_OCI_L3M_POC', 'description': 'Particulate Organic Carbon'},\n",
    "    'CARBON': {'short_name': 'PACE_OCI_L3M_CARBON', 'description': 'Phytoplankton Carbon'},\n",
    "    'IOP': {'short_name': 'PACE_OCI_L3M_IOP', 'description': 'Inherent Optical Properties'},\n",
    "    'KD': {'short_name': 'PACE_OCI_L3M_KD', 'description': 'Diffuse Attenuation'}\n",
    "}\n",
    "\n",
    "print(f\"earthaccess {earthaccess.__version__}\")\n",
    "for k, v in PACE_PRODUCTS.items(): print(f\"  {k}: {v['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autenticando...\n",
      "‚úì OK!\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Auth\n",
    "print(\"Autenticando...\")\n",
    "try:\n",
    "    auth = earthaccess.login(persist=True)\n",
    "    print(\"‚úì OK!\" if auth else \"‚ö† Falhou\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Fun√ß√µes carregadas!\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Core Functions - CHUNKED PROCESSING\n",
    "\n",
    "def parse_dates_from_file(filepath):\n",
    "    dates = []\n",
    "    skip = ('#', '=', '-', 'lista', 'total', 'date', 'unique', 'list', 'lat', 'lon')\n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.split('#')[0].strip()\n",
    "            if not line or any(line.lower().startswith(s) for s in skip): continue\n",
    "            try: dates.append(pd.to_datetime(line.split(',')[0].strip()))\n",
    "            except: pass\n",
    "    return sorted(set(dates))\n",
    "\n",
    "def expand_dates(dates, window=4):\n",
    "    expanded = set()\n",
    "    for d in dates:\n",
    "        for off in range(-window, window+1):\n",
    "            expanded.add(d + timedelta(days=off))\n",
    "    return sorted(expanded)\n",
    "\n",
    "def extract_date(filename):\n",
    "    m = re.search(r'\\.(\\d{8})\\.', str(filename))\n",
    "    return pd.to_datetime(m.group(1)) if m else None\n",
    "\n",
    "\n",
    "def download_pace_chunked(products, dates, bbox, output_dir, \n",
    "                          resolution='0p1deg', window_days=4, chunk_size=8):\n",
    "    \"\"\"\n",
    "    Download PACE data processing in CHUNKS.\n",
    "    Downloads chunk_size files at a time, saves immediately, then next chunk.\n",
    "    This gives immediate feedback and doesn't require waiting for all downloads.\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir).resolve()\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PACE DOWNLOAD (CHUNKED)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"üìÅ OUTPUT: {output_path}\")\n",
    "    \n",
    "    # Expand dates\n",
    "    if window_days > 0:\n",
    "        orig = len(dates)\n",
    "        dates = expand_dates(dates, window_days)\n",
    "        print(f\"üìÖ Datas: {orig} ‚Üí {len(dates)} (¬±{window_days}d)\")\n",
    "    \n",
    "    date_min = min(dates).strftime('%Y-%m-%d')\n",
    "    date_max = max(dates).strftime('%Y-%m-%d')\n",
    "    dates_set = {d.strftime('%Y%m%d') for d in dates}\n",
    "    \n",
    "    valid_prods = [p for p in products if p in PACE_PRODUCTS]\n",
    "    print(f\"üìä Produtos: {valid_prods}\")\n",
    "    print(f\"üó∫Ô∏è  Regi√£o: lat[{bbox['lat_min']}:{bbox['lat_max']}] lon[{bbox['lon_min']}:{bbox['lon_max']}]\")\n",
    "    print(f\"üì¶ Chunk size: {chunk_size}\")\n",
    "    \n",
    "    total_saved = 0\n",
    "    total_skipped = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    for prod_key in valid_prods:\n",
    "        short_name = PACE_PRODUCTS[prod_key]['short_name']\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üì¶ {prod_key}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Search all at once\n",
    "        print(f\"  üîç Buscando {date_min} a {date_max}...\")\n",
    "        results = earthaccess.search_data(\n",
    "            short_name=short_name,\n",
    "            temporal=(date_min, date_max),\n",
    "            granule_name=f\"*.DAY.*.{resolution}.*\"\n",
    "        )\n",
    "        \n",
    "        if not results:\n",
    "            print(f\"  ‚ö† Nenhum resultado\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  ‚úì {len(results)} granules encontrados\")\n",
    "        \n",
    "        # Filter by requested dates and existing files\n",
    "        to_process = []\n",
    "        skipped = 0\n",
    "        \n",
    "        for r in results:\n",
    "            try:\n",
    "                fname = r.data_links()[0].split('/')[-1]\n",
    "                gdate = extract_date(fname)\n",
    "                if not gdate: continue\n",
    "                dstr = gdate.strftime('%Y%m%d')\n",
    "            except: continue\n",
    "            \n",
    "            if dstr not in dates_set: continue\n",
    "            \n",
    "            out_file = output_path / f\"pace_{prod_key.lower()}_{dstr}.nc\"\n",
    "            if out_file.exists():\n",
    "                skipped += 1\n",
    "                continue\n",
    "            \n",
    "            to_process.append({'result': r, 'date_str': dstr, 'out_file': out_file})\n",
    "        \n",
    "        total_skipped += skipped\n",
    "        if skipped: print(f\"  ‚óã {skipped} j√° existem\")\n",
    "        \n",
    "        if not to_process:\n",
    "            print(f\"  ‚úì Tudo pronto!\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  üì• {len(to_process)} para baixar\")\n",
    "        \n",
    "        # Process in chunks\n",
    "        n_chunks = (len(to_process) + chunk_size - 1) // chunk_size\n",
    "        \n",
    "        for chunk_idx in range(n_chunks):\n",
    "            start = chunk_idx * chunk_size\n",
    "            end = min(start + chunk_size, len(to_process))\n",
    "            chunk = to_process[start:end]\n",
    "            \n",
    "            print(f\"\\n  --- Chunk {chunk_idx+1}/{n_chunks} ({len(chunk)} arquivos) ---\")\n",
    "            \n",
    "            with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                # Download this chunk\n",
    "                chunk_results = [item['result'] for item in chunk]\n",
    "                \n",
    "                try:\n",
    "                    downloaded = earthaccess.download(\n",
    "                        chunk_results,\n",
    "                        local_path=tmpdir,\n",
    "                        threads=min(chunk_size, 8)\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"  ‚úó Download falhou: {e}\")\n",
    "                    total_errors += len(chunk)\n",
    "                    continue\n",
    "                \n",
    "                # Process and save immediately\n",
    "                for dl_file, item in zip(downloaded, chunk):\n",
    "                    out_file = item['out_file']\n",
    "                    dstr = item['date_str']\n",
    "                    \n",
    "                    try:\n",
    "                        ds = xr.open_dataset(dl_file, engine='h5netcdf')\n",
    "                        ds_sub = ds.sel(\n",
    "                            lat=slice(bbox['lat_max'], bbox['lat_min']),\n",
    "                            lon=slice(bbox['lon_min'], bbox['lon_max'])\n",
    "                        )\n",
    "                        ds_sub.to_netcdf(out_file, engine='h5netcdf')\n",
    "                        ds_sub.close()\n",
    "                        ds.close()\n",
    "                        \n",
    "                        total_saved += 1\n",
    "                        size_mb = out_file.stat().st_size / 1e6\n",
    "                        print(f\"    ‚úì {dstr} ‚Üí {out_file.name} ({size_mb:.1f}MB)\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        total_errors += 1\n",
    "                        print(f\"    ‚úó {dstr}: {str(e)[:40]}\")\n",
    "            \n",
    "            # Show running total\n",
    "            print(f\"  [Total salvo at√© agora: {total_saved}]\")\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESULTADO\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  ‚úì Salvos: {total_saved}\")\n",
    "    print(f\"  ‚óã Existiam: {total_skipped}\")\n",
    "    print(f\"  ‚úó Erros: {total_errors}\")\n",
    "    print(f\"\\nüìÅ {output_path}\")\n",
    "    \n",
    "    files = list(output_path.glob('pace_*.nc'))\n",
    "    if files:\n",
    "        total_mb = sum(f.stat().st_size for f in files) / 1e6\n",
    "        print(f\"   {len(files)} arquivos, {total_mb:.1f} MB\")\n",
    "\n",
    "print(\"‚úì Fun√ß√µes carregadas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5-test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PACE DOWNLOAD (CHUNKED)\n",
      "============================================================\n",
      "üìÅ OUTPUT: /home/jovyan/2026-proj-Trawling4PACE/contributor_folders/leandro/pace_test\n",
      "üìä Produtos: ['CHL']\n",
      "üó∫Ô∏è  Regi√£o: lat[35:40] lon[-76:-70]\n",
      "üì¶ Chunk size: 4\n",
      "\n",
      "============================================================\n",
      "üì¶ CHL\n",
      "============================================================\n",
      "  üîç Buscando 2024-06-15 a 2024-06-15...\n",
      "  ‚úì 1 granules encontrados\n",
      "  üì• 1 para baixar\n",
      "\n",
      "  --- Chunk 1/1 (1 arquivos) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ce810b58d94b0db79d98fc38ff510e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2702feb298e43eb92d65cd9243c057e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd509224642a407899f6f71c763135d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úì 20240615 ‚Üí pace_chl_20240615.nc (0.0MB)\n",
      "  [Total salvo at√© agora: 1]\n",
      "\n",
      "============================================================\n",
      "RESULTADO\n",
      "============================================================\n",
      "  ‚úì Salvos: 1\n",
      "  ‚óã Existiam: 0\n",
      "  ‚úó Erros: 0\n",
      "\n",
      "üìÅ /home/jovyan/2026-proj-Trawling4PACE/contributor_folders/leandro/pace_test\n",
      "   1 arquivos, 0.0 MB\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Quick test\n",
    "test_out = Path('./pace_test').resolve()\n",
    "test_out.mkdir(exist_ok=True)\n",
    "\n",
    "download_pace_chunked(\n",
    "    products=['CHL'],\n",
    "    dates=[pd.to_datetime('2024-06-15')],\n",
    "    bbox={'lat_min': 35, 'lat_max': 40, 'lon_min': -76, 'lon_max': -70},\n",
    "    output_dir=test_out,\n",
    "    window_days=0,\n",
    "    chunk_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-6-ui",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2582a17b695b47c2a7fc68d43acc897d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>üõ∞Ô∏è PACE Downloader</h2><hr>'), HTML(value='<b>üìÅ Output:</b>'), VBox(children=(H‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 6: UI\n",
    "\n",
    "class FolderBrowser:\n",
    "    def __init__(self, start='.'):\n",
    "        self.cur = Path(start).resolve()\n",
    "        self.sel = self.cur\n",
    "        self.html = widgets.HTML(f\"<code>{self.cur}</code>\")\n",
    "        self.dd = widgets.Select(options=self._list(), layout=widgets.Layout(width='100%', height='100px'))\n",
    "        self.b_up = widgets.Button(description='‚¨Ü', layout=widgets.Layout(width='40px'))\n",
    "        self.b_in = widgets.Button(description='üìÇ', layout=widgets.Layout(width='40px'))\n",
    "        self.b_sel = widgets.Button(description='‚úì', button_style='success', layout=widgets.Layout(width='40px'))\n",
    "        self.txt = widgets.Text(placeholder='nova', layout=widgets.Layout(width='80px'))\n",
    "        self.b_new = widgets.Button(description='+', layout=widgets.Layout(width='40px'))\n",
    "        self.selhtml = widgets.HTML(f\"<b style='color:green'>üìÅ {self.sel}</b>\")\n",
    "        self.b_up.on_click(lambda b: self._up())\n",
    "        self.b_in.on_click(lambda b: self._enter())\n",
    "        self.b_sel.on_click(lambda b: self._select())\n",
    "        self.b_new.on_click(lambda b: self._create())\n",
    "        self.w = widgets.VBox([self.html, self.dd,\n",
    "            widgets.HBox([self.b_up, self.b_in, self.b_sel, self.txt, self.b_new]), self.selhtml])\n",
    "    def _list(self):\n",
    "        try: return ['.'] + sorted([x.name for x in self.cur.iterdir() if x.is_dir() and not x.name.startswith('.')])\n",
    "        except: return ['.']\n",
    "    def _refresh(self): self.html.value = f\"<code>{self.cur}</code>\"; self.dd.options = self._list()\n",
    "    def _up(self):\n",
    "        if self.cur.parent != self.cur: self.cur = self.cur.parent; self._refresh()\n",
    "    def _enter(self):\n",
    "        if self.dd.value and self.dd.value != '.': self.cur = self.cur / self.dd.value; self._refresh()\n",
    "    def _select(self):\n",
    "        self.sel = self.cur / self.dd.value if self.dd.value and self.dd.value != '.' else self.cur\n",
    "        self.selhtml.value = f\"<b style='color:green'>üìÅ {self.sel}</b>\"\n",
    "    def _create(self):\n",
    "        if self.txt.value: (self.cur / self.txt.value).mkdir(exist_ok=True); self.txt.value = ''; self._refresh()\n",
    "    def path(self): return str(self.sel.resolve())\n",
    "\n",
    "class FileBrowser:\n",
    "    def __init__(self, start='.', ext=('.txt','.csv','.dat')):\n",
    "        self.cur = Path(start).resolve()\n",
    "        self.ext = ext\n",
    "        self.selfile = None\n",
    "        self.html = widgets.HTML(f\"<code>{self.cur}</code>\")\n",
    "        self.dd = widgets.Select(options=self._list(), layout=widgets.Layout(width='100%', height='80px'))\n",
    "        self.b_up = widgets.Button(description='‚¨Ü', layout=widgets.Layout(width='40px'))\n",
    "        self.b_in = widgets.Button(description='üìÇ', layout=widgets.Layout(width='40px'))\n",
    "        self.b_sel = widgets.Button(description='üìÑ', button_style='info', layout=widgets.Layout(width='40px'))\n",
    "        self.selhtml = widgets.HTML(\"<i>-</i>\")\n",
    "        self.b_up.on_click(lambda b: self._up())\n",
    "        self.b_in.on_click(lambda b: self._enter())\n",
    "        self.b_sel.on_click(lambda b: self._select())\n",
    "        self.w = widgets.VBox([self.html, self.dd, widgets.HBox([self.b_up, self.b_in, self.b_sel]), self.selhtml])\n",
    "    def _list(self):\n",
    "        items = ['.']\n",
    "        try:\n",
    "            for x in sorted(self.cur.iterdir()):\n",
    "                if x.is_dir() and not x.name.startswith('.'): items.append(f\"üìÅ {x.name}\")\n",
    "            for x in sorted(self.cur.iterdir()):\n",
    "                if x.is_file() and x.suffix.lower() in self.ext: items.append(x.name)\n",
    "        except: pass\n",
    "        return items\n",
    "    def _refresh(self): self.html.value = f\"<code>{self.cur}</code>\"; self.dd.options = self._list()\n",
    "    def _up(self):\n",
    "        if self.cur.parent != self.cur: self.cur = self.cur.parent; self._refresh()\n",
    "    def _enter(self):\n",
    "        if self.dd.value and self.dd.value.startswith('üìÅ '): self.cur = self.cur / self.dd.value[2:]; self._refresh()\n",
    "    def _select(self):\n",
    "        if self.dd.value and not self.dd.value.startswith('üìÅ') and self.dd.value != '.':\n",
    "            self.selfile = self.cur / self.dd.value\n",
    "            self.selhtml.value = f\"<b style='color:blue'>üìÑ {self.selfile.name}</b>\"\n",
    "    def file(self): return str(self.selfile) if self.selfile else None\n",
    "\n",
    "fb = FolderBrowser('.')\n",
    "flb = FileBrowser('.')\n",
    "\n",
    "w_lat = widgets.FloatRangeSlider(value=[30, 50], min=-90, max=90, step=0.5, description='Lat:')\n",
    "w_lon = widgets.FloatRangeSlider(value=[-80, -60], min=-180, max=180, step=0.5, description='Lon:')\n",
    "w_products = widgets.SelectMultiple(options=list(PACE_PRODUCTS.keys()), value=['CHL', 'RRS'],\n",
    "    layout=widgets.Layout(width='150px', height='100px'))\n",
    "w_resolution = widgets.Dropdown(options=[('0.1¬∞', '0p1deg'), ('4km', '4km')], value='0p1deg', description='Res:')\n",
    "w_chunk = widgets.IntSlider(value=8, min=1, max=20, description='Chunk:')\n",
    "w_mode = widgets.Dropdown(options=['Single', 'Range', 'File'], value='Single', description='Mode:')\n",
    "w_single = widgets.DatePicker(description='Date:')\n",
    "w_start = widgets.DatePicker(description='Start:')\n",
    "w_end = widgets.DatePicker(description='End:')\n",
    "w_window = widgets.IntSlider(value=4, min=0, max=15, description='¬±days:')\n",
    "\n",
    "w_datebox = widgets.VBox([w_single])\n",
    "def on_mode(c):\n",
    "    if c['new'] == 'Single': w_datebox.children = [w_single]\n",
    "    elif c['new'] == 'Range': w_datebox.children = [w_start, w_end]\n",
    "    else: w_datebox.children = [flb.w]\n",
    "w_mode.observe(on_mode, names='value')\n",
    "\n",
    "w_btn = widgets.Button(description='üöÄ Download', button_style='primary')\n",
    "w_log = widgets.Output(layout=widgets.Layout(max_height='500px', overflow='auto'))\n",
    "\n",
    "def click(b):\n",
    "    with w_log:\n",
    "        clear_output()\n",
    "        out = fb.path()\n",
    "        print(f\"üéØ Output: {out}\")\n",
    "        \n",
    "        dates = []\n",
    "        if w_mode.value == 'Single':\n",
    "            if w_single.value: dates = [pd.to_datetime(w_single.value)]\n",
    "        elif w_mode.value == 'Range':\n",
    "            if w_start.value and w_end.value:\n",
    "                dates = pd.date_range(w_start.value, w_end.value, freq='D').tolist()\n",
    "        else:\n",
    "            f = flb.file()\n",
    "            if not f: print(\"‚ö† Arquivo!\"); return\n",
    "            print(f\"üìÑ {f}\")\n",
    "            dates = parse_dates_from_file(f)\n",
    "        \n",
    "        if not dates: print(\"‚ö† Datas!\"); return\n",
    "        prods = list(w_products.value)\n",
    "        if not prods: print(\"‚ö† Produtos!\"); return\n",
    "        \n",
    "        bbox = {'lat_min': w_lat.value[0], 'lat_max': w_lat.value[1],\n",
    "                'lon_min': w_lon.value[0], 'lon_max': w_lon.value[1]}\n",
    "        \n",
    "        download_pace_chunked(\n",
    "            products=prods, dates=dates, bbox=bbox,\n",
    "            output_dir=out,\n",
    "            resolution=w_resolution.value,\n",
    "            window_days=w_window.value,\n",
    "            chunk_size=w_chunk.value\n",
    "        )\n",
    "\n",
    "w_btn.on_click(click)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h2>üõ∞Ô∏è PACE Downloader</h2><hr>\"),\n",
    "    widgets.HTML(\"<b>üìÅ Output:</b>\"), fb.w,\n",
    "    widgets.HTML(\"<hr><b>üó∫Ô∏è Region:</b>\"), w_lat, w_lon,\n",
    "    widgets.HTML(\"<hr><b>üìä Products:</b>\"), w_products, w_resolution, w_chunk,\n",
    "    widgets.HTML(\"<hr><b>üìÖ Dates:</b>\"), w_mode, w_datebox, w_window,\n",
    "    widgets.HTML(\"<hr>\"), w_btn,\n",
    "    widgets.HTML(\"<b>Log:</b>\"), w_log\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Programmatic\n",
    "'''\n",
    "dates = parse_dates_from_file('/path/to/dates.txt')\n",
    "download_pace_chunked(\n",
    "    products=['CHL', 'RRS'],\n",
    "    dates=dates,\n",
    "    bbox={'lat_min': 30, 'lat_max': 50, 'lon_min': -80, 'lon_max': -60},\n",
    "    output_dir='/path/to/output',\n",
    "    window_days=4,\n",
    "    chunk_size=8\n",
    ")\n",
    "'''\n",
    "print(\"Descomente para usar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: Check files\n",
    "def list_files(d):\n",
    "    p = Path(d).resolve()\n",
    "    files = sorted(p.glob('pace_*.nc'))\n",
    "    if not files: print(f\"Nenhum em {p}\"); return\n",
    "    total = sum(f.stat().st_size for f in files) / 1e6\n",
    "    print(f\"{p}: {len(files)} files, {total:.1f}MB\")\n",
    "    for f in files[:5]: print(f\"  {f.name}\")\n",
    "    if len(files) > 5: print(f\"  ...+{len(files)-5}\")\n",
    "\n",
    "# list_files('./pace_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

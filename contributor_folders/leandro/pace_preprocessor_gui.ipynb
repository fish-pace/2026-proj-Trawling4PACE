{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Install dependencies\n",
    "import sys, subprocess\n",
    "pkgs = [\"pandas\", \"numpy\", \"xarray\", \"netCDF4\", \"scipy\", \"ipywidgets\"]\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + pkgs + [\"--quiet\"])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PACE Preprocessor for Fishing Correlation Analysis\n",
      "numpy 2.3.5, pandas 2.3.3, xarray 2025.12.0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Imports\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PACE Preprocessor for Fishing Correlation Analysis\")\n",
    "print(f\"numpy {np.__version__}, pandas {pd.__version__}, xarray {xr.__version__}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured products: ['carbon', 'chl', 'iop', 'poc', 'kd', 'rrs']\n",
      "Temporal window for composite: ¬±4 days\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Configuration and PACE product definitions\n",
    "\n",
    "# PACE product configuration\n",
    "PACE_PRODUCTS = {\n",
    "    'carbon': {'var': 'carbon_phyto', 'output_name': 'carbon_phyto', 'has_wavelength': False},\n",
    "    'chl': {'var': 'chlor_a', 'output_name': 'chlor_a', 'has_wavelength': False},\n",
    "    'iop': {'var': 'bbp_s', 'output_name': 'bbp_s', 'has_wavelength': False},\n",
    "    'poc': {'var': 'poc', 'output_name': 'poc', 'has_wavelength': False},\n",
    "    'kd': {'var': 'Kd', 'output_name': 'Kd_490', 'has_wavelength': True, 'target_wl': 490},\n",
    "    'rrs': {'var': 'Rrs', 'output_name': 'Rrs', 'has_wavelength': True, 'keep_all_wl': True},\n",
    "}\n",
    "\n",
    "# Temporal window for composite (¬±days)\n",
    "TEMPORAL_WINDOW = 4\n",
    "\n",
    "print(f\"Configured products: {list(PACE_PRODUCTS.keys())}\")\n",
    "print(f\"Temporal window for composite: ¬±{TEMPORAL_WINDOW} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing functions defined.\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Core processing functions\n",
    "\n",
    "def discover_pace_files(data_dir: Path) -> Dict[str, Dict[datetime, Path]]:\n",
    "    \"\"\"\n",
    "    Discover PACE files organized by product and date.\n",
    "    Expected pattern: pace_{product}_{YYYYMMDD}.nc\n",
    "    \"\"\"\n",
    "    files_by_product = defaultdict(dict)\n",
    "    \n",
    "    if not data_dir.exists():\n",
    "        return dict(files_by_product)\n",
    "    \n",
    "    pattern = re.compile(r'pace_([a-z]+)_(\\d{8})\\.nc', re.IGNORECASE)\n",
    "    \n",
    "    for f in data_dir.glob('*.nc'):\n",
    "        match = pattern.match(f.name)\n",
    "        if match:\n",
    "            product = match.group(1).lower()\n",
    "            date_str = match.group(2)\n",
    "            try:\n",
    "                date = datetime.strptime(date_str, '%Y%m%d')\n",
    "                files_by_product[product][date] = f\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    return dict(files_by_product)\n",
    "\n",
    "\n",
    "def read_pace_variable(filepath: Path, var_name: str, \n",
    "                       wavelength_target: Optional[int] = None,\n",
    "                       keep_all_wavelengths: bool = False) -> Tuple:\n",
    "    \"\"\"\n",
    "    Read a variable from a PACE file.\n",
    "    Returns (data, lats, lons, wavelengths) or (None, None, None, None) on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with xr.open_dataset(filepath) as ds:\n",
    "            if var_name not in ds.data_vars:\n",
    "                return None, None, None, None\n",
    "            \n",
    "            data = ds[var_name]\n",
    "            lats = ds['lat'].values\n",
    "            lons = ds['lon'].values\n",
    "            wavelengths = None\n",
    "            \n",
    "            # Handle wavelength dimension\n",
    "            if 'wavelength' in data.dims:\n",
    "                wavelengths = ds['wavelength'].values\n",
    "                if keep_all_wavelengths:\n",
    "                    # Keep all wavelengths\n",
    "                    pass\n",
    "                elif wavelength_target is not None:\n",
    "                    idx = np.argmin(np.abs(wavelengths - wavelength_target))\n",
    "                    data = data.isel(wavelength=idx)\n",
    "                    wavelengths = np.array([wavelengths[idx]])\n",
    "            \n",
    "            # Convert and handle fill values\n",
    "            values = data.values.astype(np.float32)\n",
    "            fill_val = data.attrs.get('_FillValue', -32767)\n",
    "            values = np.where(values == fill_val, np.nan, values)\n",
    "            values = np.where(np.abs(values) > 1e10, np.nan, values)\n",
    "            \n",
    "            return values, lats, lons, wavelengths\n",
    "            \n",
    "    except Exception as e:\n",
    "        return None, None, None, None\n",
    "\n",
    "\n",
    "def get_dates_by_priority(target: datetime, available: Dict[datetime, Path], \n",
    "                          window: int = 4) -> List[datetime]:\n",
    "    \"\"\"\n",
    "    Return dates ordered by priority for temporal filling.\n",
    "    Priority: exact date > closer dates > past dates on tie.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "    for dt in available:\n",
    "        delta = (dt - target).days\n",
    "        if -window <= delta <= window:\n",
    "            candidates.append((abs(delta), 0 if delta <= 0 else 1, dt))\n",
    "    \n",
    "    candidates.sort()\n",
    "    return [c[2] for c in candidates]\n",
    "\n",
    "\n",
    "def process_single_date(target_date: datetime,\n",
    "                        pace_files: Dict[str, Dict[datetime, Path]],\n",
    "                        mode: str = 'daily',\n",
    "                        window: int = 4) -> Optional[xr.Dataset]:\n",
    "    \"\"\"\n",
    "    Process PACE data for a single date.\n",
    "    \n",
    "    Args:\n",
    "        target_date: Date to process\n",
    "        pace_files: Dict of available files by product/date\n",
    "        mode: 'daily' (strict, exact date only) or 'composite' (search within window)\n",
    "        window: Temporal window for composite mode\n",
    "    \n",
    "    Returns:\n",
    "        xarray Dataset with all variables, or None if no data\n",
    "    \"\"\"\n",
    "    data_arrays = {}\n",
    "    lats, lons = None, None\n",
    "    rrs_wavelengths = None\n",
    "    \n",
    "    for product, config in PACE_PRODUCTS.items():\n",
    "        if product not in pace_files:\n",
    "            continue\n",
    "        \n",
    "        var_name = config['var']\n",
    "        output_name = config['output_name']\n",
    "        has_wl = config.get('has_wavelength', False)\n",
    "        target_wl = config.get('target_wl')\n",
    "        keep_all_wl = config.get('keep_all_wl', False)\n",
    "        \n",
    "        # Determine which date to use\n",
    "        if mode == 'daily':\n",
    "            # Strict mode: only exact date\n",
    "            if target_date not in pace_files[product]:\n",
    "                continue\n",
    "            filepath = pace_files[product][target_date]\n",
    "        else:\n",
    "            # Composite mode: search within window\n",
    "            dates_to_try = get_dates_by_priority(target_date, pace_files[product], window)\n",
    "            if not dates_to_try:\n",
    "                continue\n",
    "            filepath = pace_files[product][dates_to_try[0]]\n",
    "        \n",
    "        # Read data\n",
    "        data, lat_arr, lon_arr, wl = read_pace_variable(\n",
    "            filepath, var_name, target_wl, keep_all_wl\n",
    "        )\n",
    "        \n",
    "        if data is not None:\n",
    "            if keep_all_wl and wl is not None:\n",
    "                # For Rrs, store with wavelength dimension\n",
    "                data_arrays[output_name] = (data, wl)\n",
    "                rrs_wavelengths = wl\n",
    "            else:\n",
    "                data_arrays[output_name] = data\n",
    "            \n",
    "            if lats is None:\n",
    "                lats, lons = lat_arr, lon_arr\n",
    "    \n",
    "    if not data_arrays or lats is None:\n",
    "        return None\n",
    "    \n",
    "    # Calculate derived variables\n",
    "    if 'chlor_a' in data_arrays and 'carbon_phyto' in data_arrays:\n",
    "        chl = data_arrays['chlor_a']\n",
    "        carbon = data_arrays['carbon_phyto']\n",
    "        if not isinstance(chl, tuple) and not isinstance(carbon, tuple):\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                chl_c = chl / carbon\n",
    "                chl_c = np.where(np.isfinite(chl_c), chl_c, np.nan)\n",
    "            data_arrays['chl_c_ratio'] = chl_c\n",
    "    \n",
    "    # Build xarray Dataset\n",
    "    data_vars = {}\n",
    "    for name, arr in data_arrays.items():\n",
    "        if isinstance(arr, tuple):\n",
    "            # Variable with wavelength dimension (Rrs)\n",
    "            data_vars[name] = (['lat', 'lon', 'wavelength'], arr[0])\n",
    "        else:\n",
    "            data_vars[name] = (['lat', 'lon'], arr)\n",
    "    \n",
    "    coords = {'lat': lats, 'lon': lons}\n",
    "    if rrs_wavelengths is not None:\n",
    "        coords['wavelength'] = rrs_wavelengths\n",
    "    \n",
    "    ds = xr.Dataset(data_vars, coords=coords)\n",
    "    \n",
    "    # Add attributes\n",
    "    ds.attrs['title'] = f'PACE OCI {mode.capitalize()} Composite for Fishing Analysis'\n",
    "    ds.attrs['date'] = target_date.strftime('%Y-%m-%d')\n",
    "    ds.attrs['mode'] = mode\n",
    "    ds.attrs['source'] = 'NASA PACE OCI L3 products'\n",
    "    if mode == 'composite':\n",
    "        ds.attrs['temporal_window'] = f'¬±{window} days'\n",
    "    \n",
    "    # Variable attributes\n",
    "    var_attrs = {\n",
    "        'chlor_a': {'long_name': 'Chlorophyll-a concentration', 'units': 'mg m^-3'},\n",
    "        'carbon_phyto': {'long_name': 'Phytoplankton Carbon', 'units': 'mg m^-3'},\n",
    "        'bbp_s': {'long_name': 'Backscattering spectral slope (eta)', 'units': 'dimensionless'},\n",
    "        'poc': {'long_name': 'Particulate Organic Carbon', 'units': 'mg m^-3'},\n",
    "        'Kd_490': {'long_name': 'Diffuse attenuation coefficient at 490nm', 'units': 'm^-1'},\n",
    "        'chl_c_ratio': {'long_name': 'Chlorophyll:Carbon ratio', 'units': 'mg Chl / mg C'},\n",
    "        'Rrs': {'long_name': 'Remote sensing reflectance', 'units': 'sr^-1'},\n",
    "    }\n",
    "    for var in ds.data_vars:\n",
    "        if var in var_attrs:\n",
    "            ds[var].attrs.update(var_attrs[var])\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "print(\"Processing functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Browser widgets defined.\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: GUI Components - Folder and File Browsers\n",
    "\n",
    "class FolderBrowser:\n",
    "    \"\"\"Interactive folder browser widget.\"\"\"\n",
    "    \n",
    "    def __init__(self, start='.', label='Folder', must_be_in=None):\n",
    "        self.cur = Path(start).resolve()\n",
    "        self.sel = self.cur\n",
    "        self.must_be_in = Path(must_be_in).resolve() if must_be_in else None\n",
    "        self.label = label\n",
    "        \n",
    "        self.html = widgets.HTML(f\"<code>{self.cur}</code>\")\n",
    "        self.dd = widgets.Select(\n",
    "            options=self._list(), \n",
    "            layout=widgets.Layout(width='100%', height='100px')\n",
    "        )\n",
    "        self.b_up = widgets.Button(description='‚Üë Up', layout=widgets.Layout(width='70px'))\n",
    "        self.b_in = widgets.Button(description='‚Üí Enter', layout=widgets.Layout(width='80px'))\n",
    "        self.b_sel = widgets.Button(description='‚úì Select', button_style='success', \n",
    "                                    layout=widgets.Layout(width='80px'))\n",
    "        self.txt = widgets.Text(placeholder='new folder', layout=widgets.Layout(width='150px'))\n",
    "        self.b_new = widgets.Button(description='+New', layout=widgets.Layout(width='60px'))\n",
    "        self.selhtml = widgets.HTML(f\"<b>Selected:</b> <code>{self.sel}</code>\")\n",
    "        \n",
    "        self.b_up.on_click(lambda b: self._up())\n",
    "        self.b_in.on_click(lambda b: self._enter())\n",
    "        self.b_sel.on_click(lambda b: self._select())\n",
    "        self.b_new.on_click(lambda b: self._create())\n",
    "        \n",
    "        self.w = widgets.VBox([\n",
    "            widgets.HTML(f\"<b>{label}</b>\"),\n",
    "            self.html, self.dd,\n",
    "            widgets.HBox([self.b_up, self.b_in, self.b_sel, self.txt, self.b_new]),\n",
    "            self.selhtml\n",
    "        ])\n",
    "    \n",
    "    def _list(self):\n",
    "        try:\n",
    "            items = ['.']\n",
    "            for x in sorted(self.cur.iterdir()):\n",
    "                if x.is_dir() and not x.name.startswith('.'):\n",
    "                    items.append(x.name)\n",
    "            return items\n",
    "        except:\n",
    "            return ['.']\n",
    "    \n",
    "    def _refresh(self):\n",
    "        self.html.value = f\"<code>{self.cur}</code>\"\n",
    "        self.dd.options = self._list()\n",
    "    \n",
    "    def _up(self):\n",
    "        if self.cur.parent != self.cur:\n",
    "            self.cur = self.cur.parent\n",
    "            self._refresh()\n",
    "    \n",
    "    def _enter(self):\n",
    "        if self.dd.value and self.dd.value != '.':\n",
    "            p = self.cur / self.dd.value\n",
    "            if p.is_dir():\n",
    "                self.cur = p\n",
    "                self._refresh()\n",
    "    \n",
    "    def _select(self):\n",
    "        self.sel = self.cur\n",
    "        status = \"\"\n",
    "        if self.must_be_in and not str(self.sel).startswith(str(self.must_be_in)):\n",
    "            status = \" <span style='color:red'>(‚ö† must be inside data/)</span>\"\n",
    "        self.selhtml.value = f\"<b>Selected:</b> <code>{self.sel}</code>{status}\"\n",
    "    \n",
    "    def _create(self):\n",
    "        n = self.txt.value.strip()\n",
    "        if n:\n",
    "            p = self.cur / n\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            self.cur = p\n",
    "            self.sel = p\n",
    "            self.txt.value = ''\n",
    "            self._refresh()\n",
    "            self._select()\n",
    "    \n",
    "    def path(self):\n",
    "        return self.sel\n",
    "    \n",
    "    def is_valid(self):\n",
    "        if self.must_be_in:\n",
    "            return str(self.sel).startswith(str(self.must_be_in))\n",
    "        return True\n",
    "\n",
    "\n",
    "class FileBrowser:\n",
    "    \"\"\"Interactive file browser widget for date list files.\"\"\"\n",
    "    \n",
    "    def __init__(self, start='.', extensions=None):\n",
    "        self.cur = Path(start).resolve()\n",
    "        self.sel = None\n",
    "        self.ext = extensions or ['.txt', '.csv', '.dat']\n",
    "        \n",
    "        self.html = widgets.HTML(f\"<code>{self.cur}</code>\")\n",
    "        self.dd = widgets.Select(\n",
    "            options=self._list(), \n",
    "            layout=widgets.Layout(width='100%', height='120px')\n",
    "        )\n",
    "        self.b_up = widgets.Button(description='‚Üë Up', layout=widgets.Layout(width='70px'))\n",
    "        self.b_in = widgets.Button(description='‚Üí Enter', layout=widgets.Layout(width='80px'))\n",
    "        self.b_sel = widgets.Button(description='‚úì Select File', button_style='success',\n",
    "                                    layout=widgets.Layout(width='100px'))\n",
    "        self.selhtml = widgets.HTML(\"<i>No file selected</i>\")\n",
    "        \n",
    "        self.b_up.on_click(lambda b: self._up())\n",
    "        self.b_in.on_click(lambda b: self._enter())\n",
    "        self.b_sel.on_click(lambda b: self._select())\n",
    "        \n",
    "        self.w = widgets.VBox([\n",
    "            widgets.HTML(\"<b>Date List File</b>\"),\n",
    "            self.html, self.dd,\n",
    "            widgets.HBox([self.b_up, self.b_in, self.b_sel]),\n",
    "            self.selhtml\n",
    "        ])\n",
    "    \n",
    "    def _list(self):\n",
    "        try:\n",
    "            items = []\n",
    "            for x in sorted(self.cur.iterdir()):\n",
    "                if x.name.startswith('.'):\n",
    "                    continue\n",
    "                if x.is_dir():\n",
    "                    items.append(f\"üìÅ {x.name}\")\n",
    "                elif x.suffix.lower() in self.ext:\n",
    "                    items.append(f\"üìÑ {x.name}\")\n",
    "            return items if items else ['(empty)']\n",
    "        except:\n",
    "            return ['(error)']\n",
    "    \n",
    "    def _refresh(self):\n",
    "        self.html.value = f\"<code>{self.cur}</code>\"\n",
    "        self.dd.options = self._list()\n",
    "    \n",
    "    def _up(self):\n",
    "        if self.cur.parent != self.cur:\n",
    "            self.cur = self.cur.parent\n",
    "            self._refresh()\n",
    "    \n",
    "    def _enter(self):\n",
    "        v = self.dd.value\n",
    "        if v and v.startswith('üìÅ'):\n",
    "            p = self.cur / v.replace('üìÅ ', '')\n",
    "            if p.is_dir():\n",
    "                self.cur = p\n",
    "                self._refresh()\n",
    "    \n",
    "    def _select(self):\n",
    "        v = self.dd.value\n",
    "        if v and v.startswith('üìÑ'):\n",
    "            self.sel = self.cur / v.replace('üìÑ ', '')\n",
    "            self.selhtml.value = f\"<b>Selected:</b> <code>{self.sel}</code>\"\n",
    "    \n",
    "    def file(self):\n",
    "        return self.sel\n",
    "\n",
    "\n",
    "print(\"Browser widgets defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date utilities defined.\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Date parsing utilities\n",
    "\n",
    "def parse_date_file(filepath):\n",
    "    \"\"\"Parse dates from a text/csv file.\"\"\"\n",
    "    dates = []\n",
    "    skip_prefixes = ('#', '=', '-', 'lista', 'total', 'date', 'unique', 'list', 'start', 'end')\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.split('#')[0].strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if any(line.lower().startswith(s) for s in skip_prefixes):\n",
    "                continue\n",
    "            try:\n",
    "                dt = pd.to_datetime(line)\n",
    "                dates.append(dt.to_pydatetime())\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return sorted(set(dates))\n",
    "\n",
    "\n",
    "def get_dates_from_mode(mode, single_date, start_date, end_date, file_browser):\n",
    "    \"\"\"Get list of dates based on selected mode.\"\"\"\n",
    "    if mode == 'Single Date':\n",
    "        if single_date:\n",
    "            return [datetime.combine(single_date, datetime.min.time())]\n",
    "        return []\n",
    "    \n",
    "    elif mode == 'Date Range':\n",
    "        if start_date and end_date:\n",
    "            return pd.date_range(start_date, end_date, freq='D').to_pydatetime().tolist()\n",
    "        return []\n",
    "    \n",
    "    else:  # Date List File\n",
    "        filepath = file_browser.file()\n",
    "        if filepath and filepath.exists():\n",
    "            return parse_date_file(filepath)\n",
    "        return []\n",
    "\n",
    "\n",
    "print(\"Date utilities defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main processing function defined.\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Main processing function\n",
    "\n",
    "def run_processing(pace_dir, daily_dir, composite_dir, dates, \n",
    "                   process_daily, process_composite,\n",
    "                   progress_bar, log_output):\n",
    "    \"\"\"\n",
    "    Main processing loop with progress tracking.\n",
    "    \"\"\"\n",
    "    with log_output:\n",
    "        clear_output()\n",
    "        \n",
    "        # Validate inputs\n",
    "        if not dates:\n",
    "            print(\"‚ùå No dates to process!\")\n",
    "            return\n",
    "        \n",
    "        if not process_daily and not process_composite:\n",
    "            print(\"‚ùå Select at least one output type (Daily or Composite)!\")\n",
    "            return\n",
    "        \n",
    "        pace_path = Path(pace_dir)\n",
    "        if not pace_path.exists():\n",
    "            print(f\"‚ùå PACE data directory not found: {pace_path}\")\n",
    "            return\n",
    "        \n",
    "        # Create output directories\n",
    "        if process_daily:\n",
    "            daily_path = Path(daily_dir)\n",
    "            daily_path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"üìÅ Daily output: {daily_path}\")\n",
    "        \n",
    "        if process_composite:\n",
    "            composite_path = Path(composite_dir)\n",
    "            composite_path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"üìÅ Composite output: {composite_path}\")\n",
    "        \n",
    "        # Discover PACE files\n",
    "        print(f\"\\nüîç Scanning PACE files in: {pace_path}\")\n",
    "        pace_files = discover_pace_files(pace_path)\n",
    "        \n",
    "        if not pace_files:\n",
    "            print(\"‚ùå No PACE files found! Expected pattern: pace_{product}_{YYYYMMDD}.nc\")\n",
    "            return\n",
    "        \n",
    "        print(\"Found products:\")\n",
    "        for product, files in pace_files.items():\n",
    "            print(f\"   ‚Ä¢ {product}: {len(files)} files\")\n",
    "        \n",
    "        # Setup progress\n",
    "        total_tasks = len(dates) * (int(process_daily) + int(process_composite))\n",
    "        progress_bar.max = total_tasks\n",
    "        progress_bar.value = 0\n",
    "        \n",
    "        print(f\"\\nüìÖ Processing {len(dates)} dates...\")\n",
    "        print(f\"   Range: {dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        stats = {'daily_ok': 0, 'daily_skip': 0, 'daily_fail': 0,\n",
    "                 'composite_ok': 0, 'composite_skip': 0, 'composite_fail': 0}\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            date_str = date.strftime('%Y%m%d')\n",
    "            \n",
    "            # Process Daily\n",
    "            if process_daily:\n",
    "                outfile = daily_path / f\"pace_daily_{date_str}.nc\"\n",
    "                if outfile.exists():\n",
    "                    print(f\"  ‚è≠ SKIP daily {date_str} (exists)\")\n",
    "                    stats['daily_skip'] += 1\n",
    "                else:\n",
    "                    try:\n",
    "                        ds = process_single_date(date, pace_files, mode='daily')\n",
    "                        if ds is not None:\n",
    "                            # Clear encoding before saving\n",
    "                            for var in list(ds.data_vars) + list(ds.coords):\n",
    "                                if var in ds:\n",
    "                                    ds[var].encoding.clear()\n",
    "                            ds.to_netcdf(outfile)\n",
    "                            ds.close()\n",
    "                            print(f\"  ‚úÖ daily {date_str} ({len(ds.data_vars)} vars)\")\n",
    "                            stats['daily_ok'] += 1\n",
    "                        else:\n",
    "                            print(f\"  ‚ö† daily {date_str} (no data)\")\n",
    "                            stats['daily_fail'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ‚ùå daily {date_str}: {str(e)[:50]}\")\n",
    "                        stats['daily_fail'] += 1\n",
    "                \n",
    "                progress_bar.value += 1\n",
    "            \n",
    "            # Process Composite\n",
    "            if process_composite:\n",
    "                outfile = composite_path / f\"pace_composite_{date_str}.nc\"\n",
    "                if outfile.exists():\n",
    "                    print(f\"  ‚è≠ SKIP composite {date_str} (exists)\")\n",
    "                    stats['composite_skip'] += 1\n",
    "                else:\n",
    "                    try:\n",
    "                        ds = process_single_date(date, pace_files, mode='composite', \n",
    "                                                 window=TEMPORAL_WINDOW)\n",
    "                        if ds is not None:\n",
    "                            for var in list(ds.data_vars) + list(ds.coords):\n",
    "                                if var in ds:\n",
    "                                    ds[var].encoding.clear()\n",
    "                            ds.to_netcdf(outfile)\n",
    "                            ds.close()\n",
    "                            print(f\"  ‚úÖ composite {date_str} ({len(ds.data_vars)} vars)\")\n",
    "                            stats['composite_ok'] += 1\n",
    "                        else:\n",
    "                            print(f\"  ‚ö† composite {date_str} (no data)\")\n",
    "                            stats['composite_fail'] += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"  ‚ùå composite {date_str}: {str(e)[:50]}\")\n",
    "                        stats['composite_fail'] += 1\n",
    "                \n",
    "                progress_bar.value += 1\n",
    "        \n",
    "        # Summary\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"üìä PROCESSING SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        if process_daily:\n",
    "            print(f\"Daily:     ‚úÖ {stats['daily_ok']} created, \"\n",
    "                  f\"‚è≠ {stats['daily_skip']} skipped, ‚ö† {stats['daily_fail']} no data\")\n",
    "        if process_composite:\n",
    "            print(f\"Composite: ‚úÖ {stats['composite_ok']} created, \"\n",
    "                  f\"‚è≠ {stats['composite_skip']} skipped, ‚ö† {stats['composite_fail']} no data\")\n",
    "        print(\"\\n‚úÖ Done!\")\n",
    "\n",
    "\n",
    "print(\"Main processing function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5550c03afab743febb336b56208e694f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='\\n        <div style=\"background: linear-gradient(135deg, #1a5276 0%, #2e86ab 100%)‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 8: Build and display GUI\n",
    "\n",
    "# Find data directory\n",
    "data_dir = Path('./data')\n",
    "for p in ['./data', '../data', '../../data']:\n",
    "    if Path(p).exists():\n",
    "        data_dir = Path(p).resolve()\n",
    "        break\n",
    "\n",
    "# Initialize browsers\n",
    "fb_pace = FolderBrowser(start=str(data_dir), label='üìÇ PACE Input Data Directory')\n",
    "fb_daily = FolderBrowser(start=str(data_dir), label='üìÅ Daily Output (strict, no filling)', \n",
    "                         must_be_in=str(data_dir))\n",
    "fb_composite = FolderBrowser(start=str(data_dir), label='üìÅ Composite Output (¬±4 days filling)',\n",
    "                             must_be_in=str(data_dir))\n",
    "fb_datefile = FileBrowser(start=str(data_dir))\n",
    "\n",
    "# Date mode widgets\n",
    "w_mode = widgets.Dropdown(\n",
    "    options=['Single Date', 'Date Range', 'Date List File'],\n",
    "    value='Single Date',\n",
    "    description='Mode:',\n",
    "    layout=widgets.Layout(width='250px')\n",
    ")\n",
    "\n",
    "w_single = widgets.DatePicker(description='Date:', value=datetime(2025, 3, 28).date())\n",
    "w_start = widgets.DatePicker(description='Start:', value=datetime(2025, 3, 1).date())\n",
    "w_end = widgets.DatePicker(description='End:', value=datetime(2025, 3, 31).date())\n",
    "\n",
    "w_datebox = widgets.VBox([w_single])\n",
    "\n",
    "def on_mode_change(change):\n",
    "    if change['new'] == 'Single Date':\n",
    "        w_datebox.children = [w_single]\n",
    "    elif change['new'] == 'Date Range':\n",
    "        w_datebox.children = [widgets.HBox([w_start, w_end])]\n",
    "    else:\n",
    "        w_datebox.children = [fb_datefile.w]\n",
    "\n",
    "w_mode.observe(on_mode_change, 'value')\n",
    "\n",
    "# Output type checkboxes\n",
    "w_do_daily = widgets.Checkbox(value=True, description='Generate Daily (strict)', indent=False)\n",
    "w_do_composite = widgets.Checkbox(value=True, description='Generate Composite (¬±4 days)', indent=False)\n",
    "\n",
    "# Progress and log\n",
    "w_progress = widgets.IntProgress(min=0, max=1, description='Progress:', \n",
    "                                  layout=widgets.Layout(width='100%'))\n",
    "w_log = widgets.Output(layout=widgets.Layout(border='1px solid #ccc', \n",
    "                                              max_height='400px', overflow='auto'))\n",
    "\n",
    "# Process button\n",
    "w_btn = widgets.Button(\n",
    "    description='üöÄ PROCESS PACE DATA',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='100%', height='50px')\n",
    ")\n",
    "\n",
    "def on_process_click(b):\n",
    "    # Get dates\n",
    "    dates = get_dates_from_mode(\n",
    "        w_mode.value, w_single.value, w_start.value, w_end.value, fb_datefile\n",
    "    )\n",
    "    \n",
    "    # Validate output directories are different\n",
    "    if w_do_daily.value and w_do_composite.value:\n",
    "        if fb_daily.path() == fb_composite.path():\n",
    "            with w_log:\n",
    "                clear_output()\n",
    "                print(\"‚ùå Daily and Composite output directories must be different!\")\n",
    "            return\n",
    "    \n",
    "    # Run processing\n",
    "    run_processing(\n",
    "        pace_dir=fb_pace.path(),\n",
    "        daily_dir=fb_daily.path(),\n",
    "        composite_dir=fb_composite.path(),\n",
    "        dates=dates,\n",
    "        process_daily=w_do_daily.value,\n",
    "        process_composite=w_do_composite.value,\n",
    "        progress_bar=w_progress,\n",
    "        log_output=w_log\n",
    "    )\n",
    "\n",
    "w_btn.on_click(on_process_click)\n",
    "\n",
    "# Scan button to preview available data\n",
    "w_scan_btn = widgets.Button(\n",
    "    description='üîç Scan PACE Files',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "def on_scan_click(b):\n",
    "    with w_log:\n",
    "        clear_output()\n",
    "        pace_path = fb_pace.path()\n",
    "        print(f\"Scanning: {pace_path}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        pace_files = discover_pace_files(pace_path)\n",
    "        \n",
    "        if not pace_files:\n",
    "            print(\"‚ùå No PACE files found!\")\n",
    "            print(\"Expected pattern: pace_{product}_{YYYYMMDD}.nc\")\n",
    "            return\n",
    "        \n",
    "        all_dates = set()\n",
    "        for product, files in sorted(pace_files.items()):\n",
    "            dates = sorted(files.keys())\n",
    "            all_dates.update(dates)\n",
    "            date_range = f\"{dates[0].strftime('%Y-%m-%d')} to {dates[-1].strftime('%Y-%m-%d')}\"\n",
    "            print(f\"üì¶ {product:10s}: {len(files):4d} files ({date_range})\")\n",
    "        \n",
    "        all_dates = sorted(all_dates)\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"üìÖ Total unique dates: {len(all_dates)}\")\n",
    "        print(f\"   Range: {all_dates[0].strftime('%Y-%m-%d')} to {all_dates[-1].strftime('%Y-%m-%d')}\")\n",
    "\n",
    "w_scan_btn.on_click(on_scan_click)\n",
    "\n",
    "# Build UI\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"\"\"\n",
    "        <div style=\"background: linear-gradient(135deg, #1a5276 0%, #2e86ab 100%); \n",
    "                    padding: 15px; border-radius: 8px; margin-bottom: 15px;\">\n",
    "            <h2 style=\"color: white; margin: 0;\">üõ∞Ô∏è PACE Data Preprocessor</h2>\n",
    "            <p style=\"color: #d5dbdb; margin: 5px 0 0 0;\">Generate NetCDF files for Correlation Dashboard</p>\n",
    "        </div>\n",
    "    \"\"\"),\n",
    "    \n",
    "    # Input directory\n",
    "    widgets.HTML(\"<h3>1Ô∏è‚É£ Input Data</h3>\"),\n",
    "    fb_pace.w,\n",
    "    w_scan_btn,\n",
    "    \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    \n",
    "    # Output directories\n",
    "    widgets.HTML(\"<h3>2Ô∏è‚É£ Output Directories</h3>\"),\n",
    "    widgets.HTML(\"<i style='color:#666'>Both must be inside <code>data/</code> for the Correlation Dashboard to find them.</i>\"),\n",
    "    widgets.HBox([w_do_daily, w_do_composite]),\n",
    "    widgets.HTML(\"<b>Daily Output</b> (exact date, NaN if not available):\"),\n",
    "    fb_daily.w,\n",
    "    widgets.HTML(\"<b>Composite Output</b> (searches ¬±4 days for valid data):\"),\n",
    "    fb_composite.w,\n",
    "    \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    \n",
    "    # Date selection\n",
    "    widgets.HTML(\"<h3>3Ô∏è‚É£ Date Selection</h3>\"),\n",
    "    w_mode,\n",
    "    w_datebox,\n",
    "    \n",
    "    widgets.HTML(\"<hr>\"),\n",
    "    \n",
    "    # Process button\n",
    "    widgets.HTML(\"<h3>4Ô∏è‚É£ Process</h3>\"),\n",
    "    w_btn,\n",
    "    w_progress,\n",
    "    \n",
    "    widgets.HTML(\"<br><b>Log:</b>\"),\n",
    "    w_log\n",
    "])\n",
    "\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "readme",
   "metadata": {},
   "source": [
    "---\n",
    "## Output Structure\n",
    "\n",
    "### Daily Files (`pace_daily_YYYYMMDD.nc`)\n",
    "- Values from the exact date only\n",
    "- NaN if product not available on that date\n",
    "- Best for: strict temporal matching with fishing data\n",
    "\n",
    "### Composite Files (`pace_composite_YYYYMMDD.nc`)\n",
    "- Searches ¬±4 days for valid data (priority: D > D¬±1 > D¬±2 > ... > past on tie)\n",
    "- Higher data coverage\n",
    "- Best for: maximizing data availability\n",
    "\n",
    "### Variables in each file:\n",
    "| Variable | Description | Units |\n",
    "|----------|-------------|-------|\n",
    "| `chlor_a` | Chlorophyll-a concentration | mg m‚Åª¬≥ |\n",
    "| `carbon_phyto` | Phytoplankton Carbon (C_phyto) | mg m‚Åª¬≥ |\n",
    "| `bbp_s` | Backscattering spectral slope (Œ∑) | dimensionless |\n",
    "| `poc` | Particulate Organic Carbon | mg m‚Åª¬≥ |\n",
    "| `Kd_490` | Diffuse attenuation at 490nm | m‚Åª¬π |\n",
    "| `chl_c_ratio` | Chl:C ratio (growth rate proxy) | mg Chl / mg C |\n",
    "| `Rrs` | Remote sensing reflectance (all wavelengths) | sr‚Åª¬π |\n",
    "\n",
    "### Usage with Correlation Dashboard\n",
    "1. Place output folders inside the `data/` directory\n",
    "2. Use folder names like `pace_daily` and `pace_composite`\n",
    "3. The dashboard will auto-detect them when you click \"Scan Folders\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

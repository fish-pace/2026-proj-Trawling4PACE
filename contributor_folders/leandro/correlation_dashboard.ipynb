{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Install\n",
    "import sys, subprocess\n",
    "pkgs = [\"pandas\", \"numpy\", \"xarray\", \"netCDF4\", \"scipy\", \"plotly\", \"ipywidgets\", \"ipyfilechooser\", \"kaleido\"]\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + pkgs + [\"--quiet\"])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK - pandas 2.3.3\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Imports\n",
    "import os, re, json, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import display, clear_output\n",
    "warnings.filterwarnings('ignore')\n",
    "print(f\"OK - pandas {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Correlation Dashboard v7\n",
      "- NEW: Horizontal gradient option (∇)\n",
      "  Computes |∇f| in [units/km] using central diff.\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d756c310ec46bdb04a6d1aaa959005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>Correlation Dashboard v7</h2>'), Tab(children=(VBox(children=(HTML(value='<h3>1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 3: Dashboard\n",
    "\n",
    "def compute_horizontal_gradient(field, lats, lons):\n",
    "    \"\"\"\n",
    "    Compute horizontal gradient magnitude in physical units (per km).\n",
    "    \n",
    "    Uses central differences with proper spherical Earth distance calculation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    field : 2D array (lat, lon)\n",
    "    lats : 1D array of latitudes\n",
    "    lons : 1D array of longitudes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    grad_magnitude : 2D array, gradient magnitude in [field_units / km]\n",
    "    \"\"\"\n",
    "    # Earth radius in km\n",
    "    R_EARTH = 6371.0\n",
    "    \n",
    "    # Grid spacing in degrees\n",
    "    dlat = np.abs(np.gradient(lats))  # degrees\n",
    "    dlon = np.abs(np.gradient(lons))  # degrees\n",
    "    \n",
    "    # Convert to radians\n",
    "    lat_rad = np.radians(lats)\n",
    "    \n",
    "    # Distance in km for each grid cell\n",
    "    # dy = R * dlat (in radians)\n",
    "    dy_km = R_EARTH * np.radians(dlat)  # km per grid point in y\n",
    "    \n",
    "    # dx = R * cos(lat) * dlon (in radians)\n",
    "    # This varies with latitude, so we create a 2D array\n",
    "    cos_lat = np.cos(lat_rad)\n",
    "    dx_km_1d = R_EARTH * cos_lat * np.radians(np.mean(dlon))  # km per grid point in x\n",
    "    \n",
    "    # Expand to 2D for broadcasting\n",
    "    dy_km_2d = dy_km[:, np.newaxis] * np.ones((1, len(lons)))\n",
    "    dx_km_2d = dx_km_1d[:, np.newaxis] * np.ones((1, len(lons)))\n",
    "    \n",
    "    # Compute gradients using central differences (numpy.gradient)\n",
    "    # gradient returns derivative in units of [field_units / grid_points]\n",
    "    dfdy = np.gradient(field, axis=0)  # d/dlat\n",
    "    dfdx = np.gradient(field, axis=1)  # d/dlon\n",
    "    \n",
    "    # Convert to physical units [field_units / km]\n",
    "    dfdy_km = dfdy / dy_km_2d\n",
    "    dfdx_km = dfdx / dx_km_2d\n",
    "    \n",
    "    # Gradient magnitude\n",
    "    grad_mag = np.sqrt(dfdx_km**2 + dfdy_km**2)\n",
    "    \n",
    "    return grad_mag\n",
    "\n",
    "\n",
    "class NetCDFScanner:\n",
    "    def __init__(self, data_dir='./data'):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.folders = {}\n",
    "    \n",
    "    def scan(self):\n",
    "        self.folders = {}\n",
    "        if not self.data_dir.exists():\n",
    "            return {}\n",
    "        \n",
    "        for subdir in sorted(self.data_dir.iterdir()):\n",
    "            if not subdir.is_dir():\n",
    "                continue\n",
    "            nc_files = list(subdir.glob('*.nc'))\n",
    "            if not nc_files:\n",
    "                continue\n",
    "            \n",
    "            variables, has_depth, depth_levels = [], False, []\n",
    "            lon_convention = '180'\n",
    "            has_time = False\n",
    "            \n",
    "            try:\n",
    "                with xr.open_dataset(nc_files[0]) as ds:\n",
    "                    dims = set(ds.dims.keys())\n",
    "                    variables = [v for v in ds.data_vars if v not in dims]\n",
    "                    \n",
    "                    for dim in ds.dims:\n",
    "                        if any(x in dim.lower() for x in ['depth', 'lev']):\n",
    "                            has_depth = True\n",
    "                            depth_levels = ds[dim].values.tolist()\n",
    "                            break\n",
    "                    \n",
    "                    has_time = 'time' in ds.dims\n",
    "                    \n",
    "                    for coord in ['lon', 'longitude']:\n",
    "                        if coord in ds.coords:\n",
    "                            if ds[coord].values.max() > 180:\n",
    "                                lon_convention = '360'\n",
    "                            break\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            dates = {}\n",
    "            for f in nc_files:\n",
    "                m = re.search(r'(\\d{8})', f.name)\n",
    "                if m:\n",
    "                    try:\n",
    "                        dates[datetime.strptime(m.group(1), '%Y%m%d').date()] = f\n",
    "                    except: pass\n",
    "            \n",
    "            self.folders[subdir.name] = {\n",
    "                'path': subdir, 'files': nc_files, 'variables': variables,\n",
    "                'dates': dates, 'has_depth': has_depth, 'depth_levels': depth_levels,\n",
    "                'lon_convention': lon_convention, 'has_time': has_time\n",
    "            }\n",
    "        return self.folders\n",
    "    \n",
    "    def get_file(self, folder, target_date):\n",
    "        if folder not in self.folders:\n",
    "            return None\n",
    "        dates = self.folders[folder]['dates']\n",
    "        if not dates:\n",
    "            files = self.folders[folder]['files']\n",
    "            return files[0] if files else None\n",
    "        if target_date in dates:\n",
    "            return dates[target_date]\n",
    "        nearest = min(dates.keys(), key=lambda d: abs((d - target_date).days))\n",
    "        if abs((nearest - target_date).days) <= 7:\n",
    "            return dates[nearest]\n",
    "        return None\n",
    "\n",
    "\n",
    "def interpolate_nc(ds, var, lat, lon, depth_mode='surface', lon_convention='180', compute_grad=False):\n",
    "    \"\"\"\n",
    "    Interpolate NetCDF variable to lat/lon point.\n",
    "    Optionally compute horizontal gradient magnitude first.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = ds[var]\n",
    "        lat_dim = lon_dim = depth_dim = None\n",
    "        \n",
    "        for dim in data.dims:\n",
    "            dl = dim.lower()\n",
    "            if 'lat' in dl: lat_dim = dim\n",
    "            elif 'lon' in dl: lon_dim = dim\n",
    "            elif any(x in dl for x in ['depth', 'lev']): depth_dim = dim\n",
    "        \n",
    "        if not lat_dim or not lon_dim:\n",
    "            return np.nan\n",
    "        \n",
    "        # Handle time\n",
    "        if 'time' in data.dims:\n",
    "            data = data.isel(time=0)\n",
    "        \n",
    "        # Handle depth\n",
    "        if depth_dim:\n",
    "            if depth_mode == 'surface':\n",
    "                data = data.isel({depth_dim: 0})\n",
    "            elif depth_mode == 'bottom':\n",
    "                data = data.isel({depth_dim: -1})\n",
    "            elif depth_mode == 'column_mean':\n",
    "                data = data.mean(dim=depth_dim, skipna=True)\n",
    "            else:\n",
    "                data = data.isel({depth_dim: 0})\n",
    "        \n",
    "        lats = ds[lat_dim].values\n",
    "        lons = ds[lon_dim].values\n",
    "        vals = data.values\n",
    "        \n",
    "        # Handle fill values\n",
    "        vals = np.where(np.isfinite(vals) & (np.abs(vals) < 1e30), vals, np.nan)\n",
    "        \n",
    "        # Compute gradient if requested\n",
    "        if compute_grad:\n",
    "            # Need to handle NaN for gradient calculation\n",
    "            # Fill NaN temporarily with interpolation for smoother gradients\n",
    "            from scipy.ndimage import generic_filter\n",
    "            \n",
    "            # Simple approach: compute gradient, NaN will propagate to edges\n",
    "            vals = compute_horizontal_gradient(vals, lats, lons)\n",
    "        \n",
    "        # Convert query longitude if needed\n",
    "        query_lon = lon\n",
    "        if lon_convention == '360' and lon < 0:\n",
    "            query_lon = lon + 360\n",
    "        \n",
    "        # Check bounds\n",
    "        if lat < lats.min() or lat > lats.max():\n",
    "            return np.nan\n",
    "        if query_lon < lons.min() or query_lon > lons.max():\n",
    "            return np.nan\n",
    "        \n",
    "        # Ensure monotonic\n",
    "        if lats[0] > lats[-1]:\n",
    "            lats = lats[::-1]\n",
    "            vals = vals[::-1, :]\n",
    "        if lons[0] > lons[-1]:\n",
    "            lons = lons[::-1]\n",
    "            vals = vals[:, ::-1]\n",
    "        \n",
    "        interp = RegularGridInterpolator((lats, lons), vals, method='linear',\n",
    "                                         bounds_error=False, fill_value=np.nan)\n",
    "        return interp([[lat, query_lon]])[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "class CorrelationDashboard:\n",
    "    def __init__(self, data_dir='./data'):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.scanner = NetCDFScanner(data_dir)\n",
    "        self.csv_df = None\n",
    "        self.merged_df = None\n",
    "        self.corr_details = None\n",
    "        \n",
    "        self.csv_selected = []\n",
    "        self.nc_selected = []\n",
    "        \n",
    "        self._build_ui()\n",
    "    \n",
    "    def _build_ui(self):\n",
    "        style = {'description_width': 'initial'}\n",
    "        \n",
    "        # === TAB 1: CSV ===\n",
    "        self.csv_chooser = FileChooser(str(self.data_dir), filter_pattern='*.csv')\n",
    "        self.csv_chooser.register_callback(self._load_csv)\n",
    "        \n",
    "        self.lat_dd = widgets.Dropdown(description='Latitude:', style=style, layout=widgets.Layout(width='300px'))\n",
    "        self.lon_dd = widgets.Dropdown(description='Longitude:', style=style, layout=widgets.Layout(width='300px'))\n",
    "        self.date_dd = widgets.Dropdown(description='Date:', style=style, layout=widgets.Layout(width='300px'))\n",
    "        \n",
    "        self.csv_var_dd = widgets.Dropdown(description='Variable:', options=[], style=style, layout=widgets.Layout(width='250px'))\n",
    "        self.csv_log_cb = widgets.Checkbox(description='log', value=False, indent=False)\n",
    "        self.csv_add_btn = widgets.Button(description='Add', button_style='success', layout=widgets.Layout(width='60px'))\n",
    "        self.csv_add_btn.on_click(self._add_csv_var)\n",
    "        \n",
    "        self.csv_selected_box = widgets.VBox([], layout=widgets.Layout(border='1px solid #ccc', padding='5px', min_height='100px'))\n",
    "        self.csv_clear_btn = widgets.Button(description='Clear All', button_style='danger', layout=widgets.Layout(width='100px'))\n",
    "        self.csv_clear_btn.on_click(lambda b: self._clear_csv_vars())\n",
    "        \n",
    "        # === TAB 2: FILTERS ===\n",
    "        self.species_select = widgets.SelectMultiple(description='Species:', options=[],\n",
    "                                                      layout=widgets.Layout(height='200px', width='450px'), style=style)\n",
    "        self.date_start = widgets.DatePicker(description='Start:', style=style)\n",
    "        self.date_end = widgets.DatePicker(description='End:', style=style)\n",
    "        self.filter_info = widgets.HTML('')\n",
    "        self.check_filter_btn = widgets.Button(description='Check Filter', button_style='info')\n",
    "        self.check_filter_btn.on_click(self._check_filter)\n",
    "        \n",
    "        # === TAB 3: NetCDF ===\n",
    "        self.scan_btn = widgets.Button(description='Scan Folders', button_style='info')\n",
    "        self.scan_btn.on_click(self._scan_nc)\n",
    "        \n",
    "        self.nc_folder_dd = widgets.Dropdown(description='Folder:', options=[], style=style, layout=widgets.Layout(width='180px'))\n",
    "        self.nc_folder_dd.observe(self._on_folder_change, 'value')\n",
    "        self.nc_var_dd = widgets.Dropdown(description='Variable:', options=[], style=style, layout=widgets.Layout(width='180px'))\n",
    "        self.nc_depth_dd = widgets.Dropdown(description='Depth:', options=['surface', 'bottom', 'column_mean'],\n",
    "                                            value='surface', style=style, layout=widgets.Layout(width='150px'))\n",
    "        self.nc_log_cb = widgets.Checkbox(description='log', value=False, indent=False, layout=widgets.Layout(width='50px'))\n",
    "        self.nc_grad_cb = widgets.Checkbox(description='∇ grad', value=False, indent=False, layout=widgets.Layout(width='70px'))\n",
    "        self.nc_add_btn = widgets.Button(description='Add', button_style='success', layout=widgets.Layout(width='50px'))\n",
    "        self.nc_add_btn.on_click(self._add_nc_var)\n",
    "        \n",
    "        self.nc_selected_box = widgets.VBox([], layout=widgets.Layout(border='1px solid #ccc', padding='5px', min_height='100px'))\n",
    "        self.nc_clear_btn = widgets.Button(description='Clear All', button_style='danger', layout=widgets.Layout(width='100px'))\n",
    "        self.nc_clear_btn.on_click(lambda b: self._clear_nc_vars())\n",
    "        self.nc_info = widgets.HTML('')\n",
    "        \n",
    "        # === TAB 4: Extract ===\n",
    "        self.process_btn = widgets.Button(description='EXTRACT DATA', button_style='success',\n",
    "                                          layout=widgets.Layout(width='100%', height='45px'))\n",
    "        self.process_btn.on_click(self._extract)\n",
    "        self.progress = widgets.IntProgress(min=0, max=100, description='Progress:')\n",
    "        self.status = widgets.HTML('')\n",
    "        self.save_name = widgets.Text(value='correlation_data.csv', description='Output:', style=style)\n",
    "        self.save_btn = widgets.Button(description='Save CSV', button_style='warning')\n",
    "        self.save_btn.on_click(self._save)\n",
    "        self.extract_summary = widgets.HTML('')\n",
    "        \n",
    "        # === TAB 5: Plot ===\n",
    "        self.plot_btn = widgets.Button(description='PLOT CORRELATION MATRIX', button_style='primary',\n",
    "                                       layout=widgets.Layout(width='100%', height='45px'))\n",
    "        self.plot_btn.on_click(self._plot)\n",
    "        \n",
    "        self.save_plot_btn = widgets.Button(description='Save PNG + Metrics', button_style='warning')\n",
    "        self.save_plot_btn.on_click(self._save_plot_and_metrics)\n",
    "        self.plot_filename = widgets.Text(value='correlation_matrix', description='Filename:', style=style)\n",
    "        \n",
    "        self.plot_out = widgets.Output()\n",
    "        \n",
    "        self.log = widgets.Output(layout=widgets.Layout(border='1px solid #ddd', max_height='150px', overflow='auto'))\n",
    "        \n",
    "        # === Tabs ===\n",
    "        tab1 = widgets.VBox([\n",
    "            widgets.HTML('<h3>1. Load CSV & Select Variables</h3>'),\n",
    "            self.csv_chooser,\n",
    "            widgets.HTML('<b>Coordinate columns:</b>'),\n",
    "            self.lat_dd, self.lon_dd, self.date_dd,\n",
    "            widgets.HTML('<hr><b>Add CSV variables:</b>'),\n",
    "            widgets.HBox([self.csv_var_dd, self.csv_log_cb, self.csv_add_btn]),\n",
    "            widgets.HTML('<b>Selected:</b>'),\n",
    "            self.csv_selected_box,\n",
    "            self.csv_clear_btn\n",
    "        ])\n",
    "        \n",
    "        tab2 = widgets.VBox([\n",
    "            widgets.HTML('<h3>2. Filter Data (optional)</h3>'),\n",
    "            widgets.HTML('<b>Species (Ctrl+click):</b>'),\n",
    "            self.species_select,\n",
    "            widgets.HTML('<b>Date range:</b>'),\n",
    "            widgets.HBox([self.date_start, self.date_end]),\n",
    "            self.check_filter_btn,\n",
    "            self.filter_info\n",
    "        ])\n",
    "        \n",
    "        tab3 = widgets.VBox([\n",
    "            widgets.HTML('<h3>3. NetCDF Variables</h3>'),\n",
    "            self.scan_btn,\n",
    "            self.nc_info,\n",
    "            widgets.HTML('<hr><b>Add variable:</b>'),\n",
    "            widgets.HTML('<i>Options: log=log10(var), ∇grad=horizontal gradient magnitude [units/km]</i>'),\n",
    "            widgets.HBox([self.nc_folder_dd, self.nc_var_dd, self.nc_depth_dd]),\n",
    "            widgets.HBox([self.nc_log_cb, self.nc_grad_cb, self.nc_add_btn]),\n",
    "            widgets.HTML('<b>Selected:</b>'),\n",
    "            self.nc_selected_box,\n",
    "            self.nc_clear_btn\n",
    "        ])\n",
    "        \n",
    "        tab4 = widgets.VBox([\n",
    "            widgets.HTML('<h3>4. Extract & Merge</h3>'),\n",
    "            widgets.HTML('<b>Summary:</b>'),\n",
    "            self.extract_summary,\n",
    "            self.process_btn,\n",
    "            self.progress,\n",
    "            self.status,\n",
    "            widgets.HTML('<hr>'),\n",
    "            widgets.HBox([self.save_name, self.save_btn])\n",
    "        ])\n",
    "        \n",
    "        tab5 = widgets.VBox([\n",
    "            widgets.HTML('<h3>5. Correlation Matrix</h3>'),\n",
    "            self.plot_btn,\n",
    "            widgets.HBox([self.plot_filename, self.save_plot_btn]),\n",
    "            self.plot_out\n",
    "        ])\n",
    "        \n",
    "        self.tabs = widgets.Tab([tab1, tab2, tab3, tab4, tab5])\n",
    "        for i, t in enumerate(['1.CSV', '2.Filter', '3.NetCDF', '4.Extract', '5.Plot']):\n",
    "            self.tabs.set_title(i, t)\n",
    "        \n",
    "        self.tabs.observe(self._update_summary, 'selected_index')\n",
    "        \n",
    "        self.ui = widgets.VBox([\n",
    "            widgets.HTML('<h2>Correlation Dashboard v7</h2>'),\n",
    "            self.tabs,\n",
    "            widgets.HTML('<b>Log:</b>'),\n",
    "            self.log\n",
    "        ])\n",
    "    \n",
    "    def _log(self, msg):\n",
    "        with self.log:\n",
    "            print(msg)\n",
    "    \n",
    "    def _load_csv(self, chooser):\n",
    "        if not chooser.selected:\n",
    "            return\n",
    "        try:\n",
    "            self.csv_df = pd.read_csv(chooser.selected)\n",
    "            cols = list(self.csv_df.columns)\n",
    "            \n",
    "            self.lat_dd.options = cols\n",
    "            self.lon_dd.options = cols\n",
    "            self.date_dd.options = cols\n",
    "            \n",
    "            for c in cols:\n",
    "                cl = c.lower()\n",
    "                if 'lat' in cl and 'dec' in cl: self.lat_dd.value = c\n",
    "                elif 'lon' in cl and 'dec' in cl: self.lon_dd.value = c\n",
    "                elif 'gmt' in cl and 'date' in cl and '1' not in cl: self.date_dd.value = c\n",
    "            \n",
    "            numeric = sorted(self.csv_df.select_dtypes(include=[np.number]).columns.tolist())\n",
    "            self.csv_var_dd.options = numeric\n",
    "            \n",
    "            if 'SCIENTIFIC_NAME' in cols:\n",
    "                species = sorted(self.csv_df['SCIENTIFIC_NAME'].dropna().unique().tolist())\n",
    "                self.species_select.options = species\n",
    "            \n",
    "            self._log(f\"Loaded: {len(self.csv_df)} rows, {len(numeric)} numeric vars\")\n",
    "        except Exception as e:\n",
    "            self._log(f\"Error: {e}\")\n",
    "    \n",
    "    def _add_csv_var(self, b):\n",
    "        var = self.csv_var_dd.value\n",
    "        use_log = self.csv_log_cb.value\n",
    "        if not var:\n",
    "            return\n",
    "        name = f\"{var}_log\" if use_log else var\n",
    "        if any(n == name for n, _ in self.csv_selected):\n",
    "            self._log(f\"{name} already added\")\n",
    "            return\n",
    "        self.csv_selected.append((name, (var, use_log)))\n",
    "        self._refresh_csv_selected()\n",
    "        self._log(f\"Added: {name}\")\n",
    "    \n",
    "    def _remove_csv_var(self, name):\n",
    "        self.csv_selected = [(n, v) for n, v in self.csv_selected if n != name]\n",
    "        self._refresh_csv_selected()\n",
    "    \n",
    "    def _clear_csv_vars(self):\n",
    "        self.csv_selected = []\n",
    "        self._refresh_csv_selected()\n",
    "    \n",
    "    def _refresh_csv_selected(self):\n",
    "        items = []\n",
    "        for name, _ in self.csv_selected:\n",
    "            btn = widgets.Button(description='X', button_style='danger', layout=widgets.Layout(width='30px', height='25px'))\n",
    "            btn.on_click(lambda b, n=name: self._remove_csv_var(n))\n",
    "            items.append(widgets.HBox([btn, widgets.HTML(f\"<code>{name}</code>\")]))\n",
    "        if not items:\n",
    "            items = [widgets.HTML('<i style=\"color:gray\">No variables</i>')]\n",
    "        self.csv_selected_box.children = items\n",
    "    \n",
    "    def _check_filter(self, b):\n",
    "        df = self._get_filtered_df()\n",
    "        if df is not None:\n",
    "            self.filter_info.value = f\"<b style='color:green'>Filtered: {len(df)} / {len(self.csv_df)} rows</b>\"\n",
    "    \n",
    "    def _get_filtered_df(self):\n",
    "        if self.csv_df is None:\n",
    "            return None\n",
    "        df = self.csv_df.copy()\n",
    "        if self.species_select.value and 'SCIENTIFIC_NAME' in df.columns:\n",
    "            df = df[df['SCIENTIFIC_NAME'].isin(self.species_select.value)]\n",
    "        if self.date_dd.value:\n",
    "            dates = pd.to_datetime(df[self.date_dd.value], errors='coerce')\n",
    "            if self.date_start.value:\n",
    "                df = df[dates >= pd.to_datetime(self.date_start.value)]\n",
    "                dates = pd.to_datetime(df[self.date_dd.value], errors='coerce')\n",
    "            if self.date_end.value:\n",
    "                df = df[dates <= pd.to_datetime(self.date_end.value)]\n",
    "        return df\n",
    "    \n",
    "    def _scan_nc(self, b):\n",
    "        self._log(\"Scanning...\")\n",
    "        folders = self.scanner.scan()\n",
    "        if not folders:\n",
    "            self._log(\"No folders!\")\n",
    "            return\n",
    "        self.nc_folder_dd.options = list(folders.keys())\n",
    "        \n",
    "        info_lines = []\n",
    "        for fname, info in folders.items():\n",
    "            flags = []\n",
    "            if info['has_depth']:\n",
    "                flags.append(f\"{len(info['depth_levels'])} depths\")\n",
    "            if info['lon_convention'] == '360':\n",
    "                flags.append(\"lon 0-360\")\n",
    "            if not info['has_time']:\n",
    "                flags.append(\"static\")\n",
    "            flag_str = f\" <i>({', '.join(flags)})</i>\" if flags else \"\"\n",
    "            info_lines.append(f\"<li><b>{fname}</b>: {len(info['dates'])} dates, vars: {', '.join(info['variables'])}{flag_str}</li>\")\n",
    "        self.nc_info.value = f\"<ul>{''.join(info_lines)}</ul>\"\n",
    "        self._log(f\"Found {len(folders)} folders\")\n",
    "    \n",
    "    def _on_folder_change(self, change):\n",
    "        folder = change['new']\n",
    "        if folder and folder in self.scanner.folders:\n",
    "            info = self.scanner.folders[folder]\n",
    "            self.nc_var_dd.options = info['variables']\n",
    "            self.nc_depth_dd.layout.display = 'block' if info['has_depth'] else 'none'\n",
    "    \n",
    "    def _add_nc_var(self, b):\n",
    "        folder = self.nc_folder_dd.value\n",
    "        var = self.nc_var_dd.value\n",
    "        if not folder or not var:\n",
    "            return\n",
    "        info = self.scanner.folders.get(folder, {})\n",
    "        depth_mode = self.nc_depth_dd.value if info.get('has_depth') else 'surface'\n",
    "        use_log = self.nc_log_cb.value\n",
    "        use_grad = self.nc_grad_cb.value\n",
    "        \n",
    "        # Build name\n",
    "        name = f\"{folder}_{var}\"\n",
    "        if info.get('has_depth'):\n",
    "            name += f\"_{depth_mode}\"\n",
    "        if use_grad:\n",
    "            name += \"_grad\"\n",
    "        if use_log:\n",
    "            name += \"_log\"\n",
    "        \n",
    "        if any(n == name for n, _ in self.nc_selected):\n",
    "            self._log(f\"{name} already added\")\n",
    "            return\n",
    "        \n",
    "        # Store: (folder, var, depth_mode, use_log, use_grad)\n",
    "        self.nc_selected.append((name, (folder, var, depth_mode, use_log, use_grad)))\n",
    "        self._refresh_nc_selected()\n",
    "        self._log(f\"Added: {name}\")\n",
    "    \n",
    "    def _remove_nc_var(self, name):\n",
    "        self.nc_selected = [(n, v) for n, v in self.nc_selected if n != name]\n",
    "        self._refresh_nc_selected()\n",
    "    \n",
    "    def _clear_nc_vars(self):\n",
    "        self.nc_selected = []\n",
    "        self._refresh_nc_selected()\n",
    "    \n",
    "    def _refresh_nc_selected(self):\n",
    "        items = []\n",
    "        for name, _ in self.nc_selected:\n",
    "            btn = widgets.Button(description='X', button_style='danger', layout=widgets.Layout(width='30px', height='25px'))\n",
    "            btn.on_click(lambda b, n=name: self._remove_nc_var(n))\n",
    "            items.append(widgets.HBox([btn, widgets.HTML(f\"<code>{name}</code>\")]))\n",
    "        if not items:\n",
    "            items = [widgets.HTML('<i style=\"color:gray\">No variables</i>')]\n",
    "        self.nc_selected_box.children = items\n",
    "    \n",
    "    def _update_summary(self, change):\n",
    "        if change['new'] == 3:\n",
    "            csv_vars = [n for n, _ in self.csv_selected]\n",
    "            nc_vars = [n for n, _ in self.nc_selected]\n",
    "            html = f\"<ul><li>CSV ({len(csv_vars)}): {', '.join(csv_vars) or 'none'}</li>\"\n",
    "            html += f\"<li>NetCDF ({len(nc_vars)}): {', '.join(nc_vars) or 'none'}</li></ul>\"\n",
    "            self.extract_summary.value = html\n",
    "    \n",
    "    def _extract(self, b):\n",
    "        if self.csv_df is None:\n",
    "            self._log(\"Load CSV!\")\n",
    "            return\n",
    "        \n",
    "        lat_col, lon_col, date_col = self.lat_dd.value, self.lon_dd.value, self.date_dd.value\n",
    "        if not all([lat_col, lon_col, date_col]):\n",
    "            self._log(\"Select columns!\")\n",
    "            return\n",
    "        if not self.csv_selected and not self.nc_selected:\n",
    "            self._log(\"Select variables!\")\n",
    "            return\n",
    "        \n",
    "        self._log(f\"Extracting {len(self.csv_selected)} CSV + {len(self.nc_selected)} NC...\")\n",
    "        \n",
    "        source_df = self._get_filtered_df()\n",
    "        df = source_df[[lat_col, lon_col, date_col]].copy()\n",
    "        df['_date'] = pd.to_datetime(df[date_col], errors='coerce').dt.date\n",
    "        valid = df['_date'].notna() & df[lat_col].notna() & df[lon_col].notna()\n",
    "        df = df[valid].reset_index(drop=True)\n",
    "        source_df = source_df[valid].reset_index(drop=True)\n",
    "        \n",
    "        # CSV vars\n",
    "        for name, (var, use_log) in self.csv_selected:\n",
    "            vals = pd.to_numeric(source_df[var], errors='coerce').values\n",
    "            if use_log:\n",
    "                vals = np.log10(np.where(vals > 0, vals, np.nan))\n",
    "            df[name] = vals\n",
    "            self._log(f\"  {name}: {np.sum(np.isfinite(vals))}/{len(vals)}\")\n",
    "        \n",
    "        # NC vars\n",
    "        n_rows = len(df)\n",
    "        self.progress.max = len(self.nc_selected) if self.nc_selected else 1\n",
    "        self.progress.value = 0\n",
    "        \n",
    "        for vi, (name, params) in enumerate(self.nc_selected):\n",
    "            folder, var, depth_mode, use_log, use_grad = params\n",
    "            \n",
    "            self.status.value = f\"Extracting {name}...\"\n",
    "            values = np.full(n_rows, np.nan)\n",
    "            folder_info = self.scanner.folders.get(folder, {})\n",
    "            lon_conv = folder_info.get('lon_convention', '180')\n",
    "            \n",
    "            for dt, group in df.groupby('_date'):\n",
    "                nc_file = self.scanner.get_file(folder, dt)\n",
    "                if nc_file is None:\n",
    "                    continue\n",
    "                try:\n",
    "                    with xr.open_dataset(nc_file) as ds:\n",
    "                        for i in group.index:\n",
    "                            lat = df.loc[i, lat_col]\n",
    "                            lon = df.loc[i, lon_col]\n",
    "                            val = interpolate_nc(ds, var, lat, lon, depth_mode, lon_conv, compute_grad=use_grad)\n",
    "                            if use_log:\n",
    "                                val = np.log10(val) if val > 0 else np.nan\n",
    "                            values[i] = val\n",
    "                except Exception as e:\n",
    "                    self._log(f\"    Error {nc_file.name}: {e}\")\n",
    "            \n",
    "            df[name] = values\n",
    "            self.progress.value = vi + 1\n",
    "            valid_n = np.sum(np.isfinite(values))\n",
    "            self._log(f\"  {name}: {valid_n}/{n_rows}\")\n",
    "        \n",
    "        df = df.drop(columns=['_date'])\n",
    "        self.merged_df = df\n",
    "        self.status.value = f\"<b style='color:green'>Done! {n_rows} rows</b>\"\n",
    "    \n",
    "    def _save(self, b):\n",
    "        if self.merged_df is None:\n",
    "            self._log(\"No data!\")\n",
    "            return\n",
    "        self.merged_df.to_csv(self.save_name.value, index=False)\n",
    "        self._log(f\"Saved: {self.save_name.value}\")\n",
    "    \n",
    "    def _plot(self, b):\n",
    "        if self.merged_df is None:\n",
    "            self._log(\"Extract first!\")\n",
    "            return\n",
    "        \n",
    "        with self.plot_out:\n",
    "            clear_output()\n",
    "            \n",
    "            lat_col, lon_col, date_col = self.lat_dd.value, self.lon_dd.value, self.date_dd.value\n",
    "            exclude = {lat_col, lon_col, date_col}\n",
    "            num_cols = [c for c in self.merged_df.columns\n",
    "                       if c not in exclude and self.merged_df[c].dtype in [np.float64, np.int64, np.float32]]\n",
    "            \n",
    "            if len(num_cols) < 2:\n",
    "                print(\"Need >= 2 variables!\")\n",
    "                return\n",
    "            \n",
    "            n = len(num_cols)\n",
    "            df = self.merged_df\n",
    "            self._log(f\"Plotting {n}x{n}...\")\n",
    "            \n",
    "            self.corr_details = []\n",
    "            \n",
    "            fig = make_subplots(rows=n, cols=n, horizontal_spacing=0.02, vertical_spacing=0.02)\n",
    "            \n",
    "            for i, vy in enumerate(num_cols):\n",
    "                for j, vx in enumerate(num_cols):\n",
    "                    row, col = i + 1, j + 1\n",
    "                    idx = (row - 1) * n + col\n",
    "                    xref = 'x domain' if idx == 1 else f'x{idx} domain'\n",
    "                    yref = 'y domain' if idx == 1 else f'y{idx} domain'\n",
    "                    \n",
    "                    if i == j:\n",
    "                        vals = df[vx].dropna()\n",
    "                        fig.add_trace(go.Histogram(x=vals, nbinsx=20, marker_color='steelblue',\n",
    "                                                   showlegend=False), row=row, col=col)\n",
    "                        fig.add_annotation(x=0.95, y=0.95, xref=xref, yref=yref,\n",
    "                                          text=f'n={len(vals)}', showarrow=False,\n",
    "                                          font=dict(size=8), bgcolor='white')\n",
    "                    \n",
    "                    elif i > j:\n",
    "                        pair = df[[vx, vy]].dropna()\n",
    "                        n_valid = len(pair)\n",
    "                        \n",
    "                        if n_valid > 2:\n",
    "                            x, y = pair[vx].values, pair[vy].values\n",
    "                            r, p = stats.pearsonr(x, y)\n",
    "                            slope, intercept, _, _, stderr = stats.linregress(x, y)\n",
    "                            \n",
    "                            self.corr_details.append({\n",
    "                                'var_x': vx, 'var_y': vy, 'n': n_valid,\n",
    "                                'r': r, 'r2': r**2, 'p_value': p,\n",
    "                                'slope': slope, 'intercept': intercept, 'stderr': stderr\n",
    "                            })\n",
    "                            \n",
    "                            if n_valid > 5000:\n",
    "                                idx_s = np.random.choice(n_valid, 5000, replace=False)\n",
    "                                x_plot, y_plot = x[idx_s], y[idx_s]\n",
    "                            else:\n",
    "                                x_plot, y_plot = x, y\n",
    "                            \n",
    "                            fig.add_trace(go.Scatter(x=x_plot, y=y_plot, mode='markers',\n",
    "                                                     marker=dict(size=2, color='steelblue', opacity=0.3),\n",
    "                                                     showlegend=False), row=row, col=col)\n",
    "                            xl = np.array([x.min(), x.max()])\n",
    "                            fig.add_trace(go.Scatter(x=xl, y=slope*xl+intercept, mode='lines',\n",
    "                                                    line=dict(color='red', width=1.5),\n",
    "                                                    showlegend=False), row=row, col=col)\n",
    "                            \n",
    "                            rcolor = 'red' if abs(r) > 0.5 else ('darkorange' if abs(r) > 0.3 else 'black')\n",
    "                            fig.add_annotation(x=0.95, y=0.95, xref=xref, yref=yref,\n",
    "                                             text=f'r={r:.2f}<br>n={n_valid}', showarrow=False,\n",
    "                                             font=dict(size=7, color=rcolor), bgcolor='white', align='right')\n",
    "                        else:\n",
    "                            fig.add_annotation(x=0.5, y=0.5, xref=xref, yref=yref,\n",
    "                                             text=f'n={n_valid}', showarrow=False,\n",
    "                                             font=dict(size=9, color='gray'))\n",
    "                    \n",
    "                    else:\n",
    "                        pair = df[[vx, vy]].dropna()\n",
    "                        n_valid = len(pair)\n",
    "                        \n",
    "                        if n_valid > 2:\n",
    "                            r, _ = stats.pearsonr(pair[vx], pair[vy])\n",
    "                            color = 'blue' if r >= 0 else 'red'\n",
    "                            size = 10 + int(abs(r) * 6)\n",
    "                            fig.add_trace(go.Scatter(x=[0.5], y=[0.6], mode='text',\n",
    "                                                    text=[f'{r:.2f}'],\n",
    "                                                    textfont=dict(size=size, color=color),\n",
    "                                                    showlegend=False), row=row, col=col)\n",
    "                            fig.add_annotation(x=0.5, y=0.25, xref=xref, yref=yref,\n",
    "                                             text=f'n={n_valid}', showarrow=False,\n",
    "                                             font=dict(size=7, color='gray'))\n",
    "                        else:\n",
    "                            fig.add_trace(go.Scatter(x=[0.5], y=[0.5], mode='text',\n",
    "                                                    text=['--'], textfont=dict(size=10, color='gray'),\n",
    "                                                    showlegend=False), row=row, col=col)\n",
    "                        \n",
    "                        fig.update_xaxes(showticklabels=False, showgrid=False, row=row, col=col)\n",
    "                        fig.update_yaxes(showticklabels=False, showgrid=False, row=row, col=col)\n",
    "            \n",
    "            for i, v in enumerate(num_cols):\n",
    "                short = v[:15] + '..' if len(v) > 15 else v\n",
    "                fig.update_xaxes(title_text=short, row=n, col=i+1, title_font_size=7, tickfont_size=6)\n",
    "                fig.update_yaxes(title_text=short, row=i+1, col=1, title_font_size=7, tickfont_size=6)\n",
    "            \n",
    "            fig.update_layout(height=120*n, width=120*n,\n",
    "                             title=dict(text=f'Correlation Matrix ({len(df)} rows)', font_size=14),\n",
    "                             showlegend=False, margin=dict(l=60, r=20, t=40, b=60))\n",
    "            \n",
    "            self.current_fig = fig\n",
    "            fig.show()\n",
    "    \n",
    "    def _save_plot_and_metrics(self, b):\n",
    "        if not hasattr(self, 'current_fig') or self.current_fig is None:\n",
    "            self._log(\"Plot first!\")\n",
    "            return\n",
    "        \n",
    "        base = self.plot_filename.value\n",
    "        \n",
    "        try:\n",
    "            self.current_fig.write_image(f\"{base}.png\", scale=2)\n",
    "            self._log(f\"Saved: {base}.png\")\n",
    "        except Exception as e:\n",
    "            self._log(f\"PNG error: {e}\")\n",
    "        \n",
    "        if self.corr_details:\n",
    "            metrics_df = pd.DataFrame(self.corr_details)\n",
    "            metrics_df.to_csv(f\"{base}_metrics.csv\", index=False)\n",
    "            self._log(f\"Saved: {base}_metrics.csv\")\n",
    "        \n",
    "        if self.merged_df is not None:\n",
    "            self.merged_df.to_csv(f\"{base}_data.csv\", index=False)\n",
    "            self._log(f\"Saved: {base}_data.csv\")\n",
    "    \n",
    "    def show(self):\n",
    "        display(self.ui)\n",
    "\n",
    "\n",
    "# === RUN ===\n",
    "print(\"=\"*50)\n",
    "print(\"Correlation Dashboard v7\")\n",
    "print(\"- NEW: Horizontal gradient option (∇)\")\n",
    "print(\"  Computes |∇f| in [units/km] using central diff.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_dir = './data'\n",
    "for p in ['./data', '../data', '../../data']:\n",
    "    if os.path.exists(p):\n",
    "        data_dir = p\n",
    "        break\n",
    "\n",
    "app = CorrelationDashboard(data_dir)\n",
    "app.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14fc10c-bc77-4b4f-8c55-811b3e062af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
